{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNkuCNp/lsc5Cg/w0ONiROg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MaimoonaKhilji/Analysis-Report-in-Rapidminer/blob/main/Main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install agh_vqis"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-All0015rBF",
        "outputId": "f265d19f-33fd-4f79-b1bb-57c9067471c9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting agh_vqis\n",
            "  Downloading agh_vqis-3.2.1-py3-none-any.whl (2.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from agh_vqis) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from agh_vqis) (1.25.2)\n",
            "Requirement already satisfied: pandas>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from agh_vqis) (1.5.3)\n",
            "Collecting PIMS>=0.5 (from agh_vqis)\n",
            "  Downloading PIMS-0.6.1.tar.gz (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scikit-image>=0.19.2 in /usr/local/lib/python3.10/dist-packages (from agh_vqis) (0.19.3)\n",
            "Collecting slicerator>=1.1.0 (from agh_vqis)\n",
            "  Downloading slicerator-1.1.0-py3-none-any.whl (10 kB)\n",
            "Collecting scenedetect>=0.6.0.3 (from agh_vqis)\n",
            "  Downloading scenedetect-0.6.2-py3-none-any.whl (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.1/117.1 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-python>=4.6.0.66 in /usr/local/lib/python3.10/dist-packages (from agh_vqis) (4.8.0.76)\n",
            "Collecting xgboost==1.7.5 (from agh_vqis)\n",
            "  Downloading xgboost-1.7.5-py3-none-manylinux2014_x86_64.whl (200.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.3/200.3 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-learn==1.2.0 (from agh_vqis)\n",
            "  Downloading scikit_learn-1.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting av>=9.0.0 (from agh_vqis)\n",
            "  Downloading av-11.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.9/32.9 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpeg-python>=0.2.0 (from agh_vqis)\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.2.0->agh_vqis) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.2.0->agh_vqis) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.2.0->agh_vqis) (3.3.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from ffmpeg-python>=0.2.0->agh_vqis) (0.18.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.1->agh_vqis) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.1->agh_vqis) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.1->agh_vqis) (4.48.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.1->agh_vqis) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.1->agh_vqis) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.1->agh_vqis) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.1->agh_vqis) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.1->agh_vqis) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.2->agh_vqis) (2023.4)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (from PIMS>=0.5->agh_vqis) (2.31.6)\n",
            "Requirement already satisfied: Click in /usr/local/lib/python3.10/dist-packages (from scenedetect>=0.6.0.3->agh_vqis) (8.1.7)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from scenedetect>=0.6.0.3->agh_vqis) (4.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from scenedetect>=0.6.0.3->agh_vqis) (4.66.2)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.19.2->agh_vqis) (3.2.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.19.2->agh_vqis) (2024.2.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.19.2->agh_vqis) (1.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.5.1->agh_vqis) (1.16.0)\n",
            "Building wheels for collected packages: PIMS\n",
            "  Building wheel for PIMS (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PIMS: filename=PIMS-0.6.1-py3-none-any.whl size=82615 sha256=8b5e4b060ac91f21e07937cac41c645863f54d1dd861eaf087fdbb144ff04648\n",
            "  Stored in directory: /root/.cache/pip/wheels/cc/bf/3e/bfa77232d942f8244145f9c713b6b38f6ef04b6fb5c021c114\n",
            "Successfully built PIMS\n",
            "Installing collected packages: slicerator, scenedetect, ffmpeg-python, av, xgboost, scikit-learn, PIMS, agh_vqis\n",
            "  Attempting uninstall: xgboost\n",
            "    Found existing installation: xgboost 2.0.3\n",
            "    Uninstalling xgboost-2.0.3:\n",
            "      Successfully uninstalled xgboost-2.0.3\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.2.2\n",
            "    Uninstalling scikit-learn-1.2.2:\n",
            "      Successfully uninstalled scikit-learn-1.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "bigframes 0.21.0 requires scikit-learn>=1.2.2, but you have scikit-learn 1.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed PIMS-0.6.1 agh_vqis-3.2.1 av-11.0.0 ffmpeg-python-0.2.0 scenedetect-0.6.2 scikit-learn-1.2.0 slicerator-1.1.0 xgboost-1.7.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tMMQlqsI5TIJ"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python\n",
        "# coding: utf-8\n",
        "\n",
        "# In[ ]:\n",
        "\n",
        "\n",
        "from agh_vqis import process_single_mm_file, VQIs\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import shutil\n",
        "# from sklearn.tree import DecisionTreeClassifier\n",
        "# import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import pickle\n",
        "\n",
        "\n",
        "RECALC = False\n",
        "\n",
        "\n",
        "def read_vqis(my_file):\n",
        "    \"\"\"\n",
        "    :param my_file: The name of the file to be read.\n",
        "    :return: The data frame obtained from reading the CSV file.\n",
        "\n",
        "    This method reads a CSV file located in the specified directory path and with the given file name. It then\n",
        "    processes the contents of the file, adds a 'Frame' column with the value of * the file name, and removes the file\n",
        "    from the directory. Finally, it returns the resulting data frame.\n",
        "    \"\"\"\n",
        "    process_single_mm_file(Path(my_file))\n",
        "    my_df = pd.read_csv(\n",
        "        f\"VQIs_for_{my_file[my_file.rfind('/')+1:-3]}csv\"\n",
        "    )  # Load the CSV file\n",
        "    my_df[\"Frame\"] = my_file\n",
        "    os.remove(f\"VQIs_for_{my_file[my_file.rfind('/')+1:-3]}csv\")  # Remove the file\n",
        "    return my_df\n",
        "\n",
        "\n",
        "datasets = {\"raw\": \"src\", \"reference\": \"pvs\"}\n",
        "vqis = {}\n",
        "for dataset in datasets:\n",
        "    directory_path = datasets[dataset]  # Specify the directory path\n",
        "\n",
        "    if RECALC:\n",
        "        # file_list = [\n",
        "        #     file\n",
        "        #     for file in os.listdir(directory_path)\n",
        "        #     if os.path.isfile(os.path.join(directory_path, file))\n",
        "        # ]  # Create a list of files in the given directory\n",
        "\n",
        "        file_list = []\n",
        "        for root, dirs, files in os.walk(\n",
        "            directory_path\n",
        "        ):  # Create a list of files in the given directory\n",
        "            for file in files:\n",
        "                file_list.append(os.path.join(root, file))\n",
        "        # print(file_list)\n",
        "        # exit(0)\n",
        "\n",
        "        df = read_vqis(file_list[0])\n",
        "\n",
        "        for file in file_list[1:]:\n",
        "            new_row = read_vqis(file)\n",
        "            df = pd.concat(\n",
        "                [df, new_row], axis=0\n",
        "            )  # Add the new row to the existing DataFrame\n",
        "\n",
        "        with open(f\"VQIs_for_{dataset}.pkl\", \"wb\") as f:\n",
        "            pickle.dump(df, f)  # Writing to disk\n",
        "    with open(f\"VQIs_for_{dataset}.pkl\", \"rb\") as f:\n",
        "        vqis[dataset] = pickle.load(f)  # Reading from disk\n",
        "    #Display the first five rows\n",
        "    #print(vqis[dataset].head())\n",
        "    print(vqis[dataset].describe())\n",
        "y_raw = pd.DataFrame(\n",
        "    {\"Class\": [\"raw\"] * vqis[\"raw\"].shape[0]}\n",
        ")  # Create a DataFrame with one column and rows with the 'raw' value\n",
        "y_ref = pd.DataFrame(\n",
        "    {\"Class\": [\"reference\"] * vqis[\"reference\"].shape[0]}\n",
        ")  # Create a DataFrame with one column and rows with the 'reference' value\n",
        "x = pd.concat([vqis[\"raw\"], vqis[\"reference\"]], axis=0)\n",
        "y = pd.concat([y_raw, y_ref], axis=0)\n",
        "#del x[\"Frame\"]\n",
        "del x[\"Slice\"]\n",
        "print(x)\n",
        "print(y)\n",
        "print(y.describe())\n",
        "print(y.value_counts())\n",
        "print(type(y))\n",
        "# y[\"Class\"] = np.random.choice([\"raw\", \"reference\"], size=len(y))\n",
        "# print(y.value_counts())\n",
        "# print(y.describe())\n",
        "# clf = DecisionTreeClassifier()\n",
        "print(\"-----------------------------------------------------------------------\")\n",
        "print(x.iloc[:,1:])\n",
        "clf = RandomForestClassifier()\n",
        "clf.fit(x.iloc[:,1:], y)\n",
        "print(clf.feature_importances_)\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
        "\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)\n",
        "clf.fit(x_train.iloc[:,1:], y_train)\n",
        "print(clf.score(x_test.iloc[:,1:], y_test))\n",
        "\n",
        "print(\"+++++++++++++++++++++++++++++++++++++\")\n",
        "#print(x.iloc[[5]])\n",
        "df1=x_test['Frame']\n",
        "del x_test[\"Frame\"]\n",
        "\n",
        "for i in range(0,len(x_test)):\n",
        "\n",
        "    pred=clf.predict(x_test.iloc[[i]])\n",
        "    print(pred)\n",
        "    actual = y_test.iloc[[i]]\n",
        "    print(actual)\n",
        "    print(\"======================\",df1.values[i])\n",
        "    source = df1.values[i] # Assuming you want the file path from the 6th row\n",
        "    # Construct the source and destination paths\n",
        "    source_path = f\"{source}\"\n",
        "\n",
        "    if pred != actual.values:\n",
        "        if actual.values == \"raw\":\n",
        "            shutil.copy(source_path, 'wrong prediction/raw/')\n",
        "        else:\n",
        "            shutil.copy(source_path, 'wrong prediction/reference/')\n",
        "\n"
      ]
    }
  ]
}